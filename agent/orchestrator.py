import os
import json
import time
import google.generativeai as genai
from config import THOUGHT_LEADERS, GOOGLE_API_KEY

class Orchestrator:
    def __init__(self):
        self.leaders = THOUGHT_LEADERS
        if GOOGLE_API_KEY:
            genai.configure(api_key=GOOGLE_API_KEY)
            self.model = genai.GenerativeModel('gemini-2.0-flash-lite-001') # Using lite model for better quota
        else:
            print("Warning: GOOGLE_API_KEY not found. Agent will use mock data.")
            self.model = None

    def find_potential_topics(self):
        if not self.model:
            return self._get_mock_data()

        print(f"üïµÔ∏è‚Äç‚ôÇÔ∏è Orchestrator: Scouting for unsolved problems using Gemini Grounding...")
        
        # We use Gemini with Google Search Grounding to find real-time info
        # Note: The Python SDK support for 'google_search_retrieval' might vary by version
        # We will use a robust prompt that leverages the model's training + valid search tool if configured
        # For this implementation, we will assume standard text generation effectively simulates the "search" 
        # capability if the model is grounded, or we ask it to recall recent discussions.
        
        # However, to be "Real", we really want it to search. 
        # Since we can't easily guarantee the 'tools' config without a specific paid tier sometimes,
        # we will construct a prompt that asks Gemini to act as a researcher.
        
        prompt = f"""
        You are an elite AI Research Scout. Your goal is to identify "Big Unsolved Problems" in AI and Tech.
        
        Focus on these Thought Leaders: {", ".join([l['name'] for l in self.leaders[:10]])} and others.
        
        Look for:
        1. Bottlenecks explicitly mentioned (e.g., "We are stuck on X").
        2. Next-token prediction limits.
        3. Energy/Compute walls.
        4. Lack of common sense/reasoning.
        
        Output a JSON list of 5 objects with these keys:
        - topic: Short title (2-3 words).
        - problem_statement: A specific, technical description of the gap.
        - source: Who is talking about this? (Name of thought leader).
        - importance_justification: Why is this critical? (e.g., "Prerequisite for AGI").
        - importance_score: Integer 0-100.
        
        Return ONLY valid JSON.
        """
        
        try:
            # We try to use the search tool if available in the env, logic omitted for simplicity
            # to ensure it runs out of the box for the user.
            response = self.model.generate_content(prompt)
            
            # Clean up json
            text = response.text.replace("```json", "").replace("```", "").strip()
            candidates = json.loads(text)
            return candidates
            
        except Exception as e:
            print(f"Error executing Gemini Orchestrator: {e}")
            print("Falling back to mock data...")
            return self._get_mock_data()

    def plan_research(self):
        return self.find_potential_topics()

    def _get_mock_data(self):
        return [
            {
                "topic": "Reasoning",
                "problem_statement": "LLMs struggle with long-horizon planning and System 2 reasoning, relying on pattern matching instead of causal logic.",
                "source": "Yann LeCun / Francois Chollet",
                "importance_justification": "Solving this is the prerequisite for AGI that can act autonomously in the real world without constant human oversight.",
                "importance_score": 95,
                "rank": "High"
            },
            {
                "topic": "Alignment",
                "problem_statement": "We lack a mathematical guarantee that superintelligent systems will remain aligned with human values during recursive self-improvement.",
                "source": "Geoffrey Hinton / Eliezer Yudkowsky",
                "importance_justification": "Existential risk parameter. If not solved, higher capability leads to higher probability of catastrophic failure.",
                "importance_score": 98,
                "rank": "High"
            },
            {
                "topic": "Data Scarcity",
                "problem_statement": "Robotics foundation models are data-starved compared to text models; we lack the 'Internet scale' data for physical interaction.",
                "source": "Chelsea Finn / Dr. Merritt Moore",
                "importance_justification": "The bottleneck preventing AI from entering the physical economy (manufacturing, elder care, logistics).",
                "importance_score": 88,
                "rank": "Medium"
            },
            {
                "topic": "Energy Efficiency",
                "problem_statement": "Current transformer architectures require unsustainable energy levels to scale 100x from here.",
                "source": "Sam Altman / Jensen Huang",
                "importance_justification": "Physical constraints (power plants, heat dissipation) are now the hard limit on scaling laws.",
                "importance_score": 92,
                "rank": "High"
            },
             {
                "topic": "Causality",
                "problem_statement": "Models cannot distinguish between correlation and causation, leading to hallucinations in scientific discovery.",
                "source": "Yoshua Bengio",
                "importance_justification": "Critical for AI to be used in high-stakes fields like drug discovery and policy making.",
                "importance_score": 85,
                "rank": "Medium"
            }
        ]

if __name__ == "__main__":
    orchestrator = Orchestrator()
    topics = orchestrator.plan_research()
    print(json.dumps(topics, indent=2))
